{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8acd039e-c34d-4290-9b9a-df16b11bf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "import time\n",
    "import uuid\n",
    "import heapq\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Set, Any, Optional, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import types\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('TaskScheduler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633cd877-3051-41d5-a568-c55214dc876c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591ff3b6-b54c-4c6e-84a3-91165a488042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerializableTask:\n",
    "    \"\"\"A serializable representation of a task for inter-process communication\"\"\"\n",
    "    def __init__(self, task_id: str, func_name: str, func_module: str, \n",
    "                 func_code: str, args: tuple, kwargs: dict, timeout: Optional[float]):\n",
    "        self.task_id = task_id\n",
    "        self.func_name = func_name\n",
    "        self.func_module = func_module\n",
    "        self.func_code = func_code\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"Execute the task by reconstructing the function\"\"\"\n",
    "        try:\n",
    "            # For simple cases, try to get the function from the module\n",
    "            if self.func_module and self.func_name:\n",
    "                module = __import__(self.func_module, fromlist=[self.func_name])\n",
    "                func = getattr(module, self.func_name)\n",
    "            else:\n",
    "                # Fallback: use exec (be careful with this in production)\n",
    "                local_scope = {}\n",
    "                exec(self.func_code, globals(), local_scope)\n",
    "                func = local_scope.get(self.func_name)\n",
    "            \n",
    "            if not func:\n",
    "                raise ValueError(f\"Function {self.func_name} not found\")\n",
    "            \n",
    "            # Execute the function\n",
    "            result = func(*self.args, **self.kwargs)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to execute task {self.task_id}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1605dd-d538-46e9-8430-e9a00ba0f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    def __init__(self, task_id: str, func: Callable, args: tuple = (), kwargs: dict = None,\n",
    "                 priority: TaskPriority = TaskPriority.NORMAL, dependencies: List[str] = None,\n",
    "                 timeout: Optional[float] = None, retries: int = 0):\n",
    "        self.task_id = task_id\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs or {}\n",
    "        self.priority = priority\n",
    "        self.dependencies = dependencies or []\n",
    "        self.timeout = timeout\n",
    "        self.retries = retries\n",
    "        self.retries_left = retries\n",
    "        self.status = TaskStatus.PENDING\n",
    "        self.result = None\n",
    "        self.error = None\n",
    "        self.created_at = time.time()\n",
    "        self.started_at = None\n",
    "        self.completed_at = None\n",
    "        self.worker_id = None\n",
    "\n",
    "    def to_serializable(self) -> SerializableTask:\n",
    "        \"\"\"Convert to serializable format for inter-process communication\"\"\"\n",
    "        func_name = self.func.__name__\n",
    "        func_module = self.func.__module__\n",
    "        \n",
    "        # Get function source code as fallback\n",
    "        try:\n",
    "            func_code = pickle.dumps(self.func)  # Try to pickle the function\n",
    "        except:\n",
    "            func_code = f\"# Function {func_name} from {func_module}\"\n",
    "        \n",
    "        return SerializableTask(\n",
    "            task_id=self.task_id,\n",
    "            func_name=func_name,\n",
    "            func_module=func_module,\n",
    "            func_code=func_code,\n",
    "            args=self.args,\n",
    "            kwargs=self.kwargs,\n",
    "            timeout=self.timeout\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d4d486-9d1f-4901-8125-2141aad3dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker:\n",
    "    def __init__(self, worker_id: str, task_queue: mp.Queue, result_queue: mp.Queue):\n",
    "        self.worker_id = worker_id\n",
    "        self.task_queue = task_queue\n",
    "        self.result_queue = result_queue\n",
    "        self.current_task = None\n",
    "        self.is_running = True\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Worker process main loop\"\"\"\n",
    "        logger.info(f\"Worker {self.worker_id} started\")\n",
    "        \n",
    "        while self.is_running:\n",
    "            try:\n",
    "                # Get task from queue with timeout to allow graceful shutdown\n",
    "                task_data = self.task_queue.get(timeout=1.0)\n",
    "                if task_data is None:  # Shutdown signal\n",
    "                    break\n",
    "                    \n",
    "                serializable_task = task_data\n",
    "                self.current_task = serializable_task.task_id\n",
    "                \n",
    "                logger.info(f\"Worker {self.worker_id} executing task {self.current_task}\")\n",
    "                \n",
    "                # Execute task with timeout\n",
    "                try:\n",
    "                    if serializable_task.timeout:\n",
    "                        result = self._execute_with_timeout(serializable_task, serializable_task.timeout)\n",
    "                    else:\n",
    "                        result = serializable_task.execute()\n",
    "                    \n",
    "                    self.result_queue.put((serializable_task.task_id, result, None, self.worker_id))\n",
    "                    logger.info(f\"Worker {self.worker_id} completed task {self.current_task}\")\n",
    "                    \n",
    "                except asyncio.TimeoutError:\n",
    "                    self.result_queue.put((serializable_task.task_id, None, \"timeout\", self.worker_id))\n",
    "                    logger.warning(f\"Worker {self.worker_id} timeout on task {self.current_task}\")\n",
    "                except Exception as e:\n",
    "                    self.result_queue.put((serializable_task.task_id, None, str(e), self.worker_id))\n",
    "                    logger.error(f\"Worker {self.worker_id} failed task {self.current_task}: {str(e)}\")\n",
    "                    \n",
    "            except:\n",
    "                continue  # Timeout for graceful shutdown\n",
    "                \n",
    "        logger.info(f\"Worker {self.worker_id} stopped\")\n",
    "\n",
    "    def _execute_with_timeout(self, task: SerializableTask, timeout: float):\n",
    "        \"\"\"Execute function with timeout\"\"\"\n",
    "        import concurrent.futures\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            future = executor.submit(task.execute)\n",
    "            try:\n",
    "                return future.result(timeout=timeout)\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                raise asyncio.TimeoutError(f\"Task timeout after {timeout} seconds\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.is_running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d9fbb99-db4f-4779-a973-ac9b8cc263bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_running_task(duration: float, task_id: str):\n",
    "    \"\"\"Example task function that runs for a specified duration\"\"\"\n",
    "    print(f\"Task {task_id} running for {duration} seconds\")\n",
    "    time.sleep(duration)\n",
    "    return f\"Task {task_id} completed after {duration}s\"\n",
    "\n",
    "def failing_task():\n",
    "    \"\"\"Example task that always fails\"\"\"\n",
    "    raise ValueError(\"This task is designed to fail\")\n",
    "\n",
    "def computation_task(x: int, y: int):\n",
    "    \"\"\"Example computation task\"\"\"\n",
    "    return x * y\n",
    "\n",
    "def data_processing_task(data: list):\n",
    "    \"\"\"Example data processing task\"\"\"\n",
    "    return sum(data) / len(data) if data else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9c43dd4-649c-4cf2-92a0-8ee099033ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedTaskScheduler:\n",
    "    def __init__(self, num_workers: int = 4, max_retries: int = 3):\n",
    "        self.num_workers = num_workers\n",
    "        self.max_retries = max_retries\n",
    "        \n",
    "        # Task management\n",
    "        self.tasks: Dict[str, Task] = {}\n",
    "        self.pending_tasks: List[PrioritizedTask] = []\n",
    "        self.running_tasks: Dict[str, Task] = {}\n",
    "        self.completed_tasks: Dict[str, Task] = {}\n",
    "        self.failed_tasks: Dict[str, Task] = {}\n",
    "        \n",
    "        # Dependency tracking\n",
    "        self.task_dependencies: Dict[str, Set[str]] = {}\n",
    "        self.dependents: Dict[str, Set[str]] = {}\n",
    "        \n",
    "        # Worker management\n",
    "        self.workers: Dict[str, Worker] = {}\n",
    "        self.worker_processes: Dict[str, mp.Process] = {}\n",
    "        \n",
    "        # Queues\n",
    "        self.task_queue = mp.Queue()\n",
    "        self.result_queue = mp.Queue()\n",
    "        \n",
    "        # Synchronization\n",
    "        self.lock = threading.Lock()\n",
    "        self.scheduler_thread = None\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Monitoring\n",
    "        self.metrics = {\n",
    "            'tasks_completed': 0,\n",
    "            'tasks_failed': 0,\n",
    "            'tasks_cancelled': 0,\n",
    "            'tasks_timed_out': 0,\n",
    "            'workers_created': 0,\n",
    "            'workers_failed': 0\n",
    "        }\n",
    "        \n",
    "        # Start workers\n",
    "        self._start_workers()\n",
    "\n",
    "    def _start_workers(self):\n",
    "        \"\"\"Initialize and start worker processes\"\"\"\n",
    "        for i in range(self.num_workers):\n",
    "            self._add_worker()\n",
    "\n",
    "    def _add_worker(self):\n",
    "        \"\"\"Add a new worker process\"\"\"\n",
    "        worker_id = f\"worker-{uuid.uuid4().hex[:8]}\"\n",
    "        worker = Worker(worker_id, self.task_queue, self.result_queue)\n",
    "        process = mp.Process(target=worker.run)\n",
    "        \n",
    "        self.workers[worker_id] = worker\n",
    "        self.worker_processes[worker_id] = process\n",
    "        process.start()\n",
    "        \n",
    "        self.metrics['workers_created'] += 1\n",
    "        logger.info(f\"Started worker {worker_id}\")\n",
    "\n",
    "    def submit_task(self, func: Callable, args: tuple = (), kwargs: dict = None,\n",
    "                   priority: TaskPriority = TaskPriority.NORMAL, \n",
    "                   dependencies: List[str] = None, timeout: Optional[float] = None,\n",
    "                   retries: int = 0) -> str:\n",
    "        \"\"\"Submit a new task to the scheduler\"\"\"\n",
    "        # Validate that the function can be serialized\n",
    "        try:\n",
    "            # Test if function can be pickled\n",
    "            pickle.dumps(func)\n",
    "        except (AttributeError, pickle.PicklingError) as e:\n",
    "            raise ValueError(f\"Function {func.__name__} cannot be serialized. \"\n",
    "                           f\"Use module-level functions instead of local functions or lambdas. Error: {e}\")\n",
    "        \n",
    "        task_id = f\"task-{uuid.uuid4().hex[:8]}\"\n",
    "        task = Task(task_id, func, args, kwargs, priority, dependencies, timeout, retries)\n",
    "        \n",
    "        with self.lock:\n",
    "            self.tasks[task_id] = task\n",
    "            \n",
    "            # Set up dependency tracking\n",
    "            if dependencies:\n",
    "                self.task_dependencies[task_id] = set(dependencies)\n",
    "                for dep_id in dependencies:\n",
    "                    if dep_id not in self.dependents:\n",
    "                        self.dependents[dep_id] = set()\n",
    "                    self.dependents[dep_id].add(task_id)\n",
    "            \n",
    "            # Add to pending queue if no dependencies\n",
    "            if not dependencies or all(dep_id in self.completed_tasks for dep_id in dependencies):\n",
    "                heapq.heappush(self.pending_tasks, \n",
    "                             PrioritizedTask(priority.value, task.created_at, task))\n",
    "                logger.info(f\"Submitted task {task_id} with priority {priority.name}\")\n",
    "            else:\n",
    "                logger.info(f\"Submitted task {task_id} waiting for dependencies\")\n",
    "        \n",
    "        return task_id\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the task scheduler\"\"\"\n",
    "        if self.is_running:\n",
    "            return\n",
    "            \n",
    "        self.is_running = True\n",
    "        self.scheduler_thread = threading.Thread(target=self._scheduler_loop)\n",
    "        self.scheduler_thread.start()\n",
    "        logger.info(\"Task scheduler started\")\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the task scheduler and all workers\"\"\"\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Stop workers\n",
    "        for worker_id, process in self.worker_processes.items():\n",
    "            self.task_queue.put(None)  # Send shutdown signal\n",
    "            process.join(timeout=5.0)\n",
    "            if process.is_alive():\n",
    "                process.terminate()\n",
    "        \n",
    "        if self.scheduler_thread:\n",
    "            self.scheduler_thread.join()\n",
    "            \n",
    "        logger.info(\"Task scheduler stopped\")\n",
    "\n",
    "    def _scheduler_loop(self):\n",
    "        \"\"\"Main scheduler loop\"\"\"\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                # Process completed tasks\n",
    "                self._process_results()\n",
    "                \n",
    "                # Schedule pending tasks\n",
    "                self._schedule_tasks()\n",
    "                \n",
    "                # Handle worker failures\n",
    "                self._check_worker_health()\n",
    "                \n",
    "                # Small sleep to prevent busy waiting\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Scheduler error: {str(e)}\")\n",
    "                time.sleep(1)  # Backoff on error\n",
    "\n",
    "    def _process_results(self):\n",
    "        \"\"\"Process results from workers\"\"\"\n",
    "        while not self.result_queue.empty():\n",
    "            try:\n",
    "                task_id, result, error, worker_id = self.result_queue.get_nowait()\n",
    "                \n",
    "                with self.lock:\n",
    "                    if task_id not in self.tasks:\n",
    "                        logger.warning(f\"Received result for unknown task {task_id}\")\n",
    "                        continue\n",
    "                    \n",
    "                    task = self.tasks[task_id]\n",
    "                    task.worker_id = worker_id\n",
    "                    \n",
    "                    if error == \"timeout\":\n",
    "                        task.status = TaskStatus.TIMEOUT\n",
    "                        task.error = \"Task execution timed out\"\n",
    "                        self.failed_tasks[task_id] = task\n",
    "                        self.metrics['tasks_timed_out'] += 1\n",
    "                        logger.warning(f\"Task {task_id} timed out\")\n",
    "                        \n",
    "                    elif error:\n",
    "                        if task.retries_left > 0:\n",
    "                            # Retry the task\n",
    "                            task.retries_left -= 1\n",
    "                            task.status = TaskStatus.PENDING\n",
    "                            heapq.heappush(self.pending_tasks, \n",
    "                                         PrioritizedTask(task.priority.value, \n",
    "                                                       task.created_at, task))\n",
    "                            logger.info(f\"Retrying task {task_id}, {task.retries_left} retries left\")\n",
    "                        else:\n",
    "                            task.status = TaskStatus.FAILED\n",
    "                            task.error = error\n",
    "                            self.failed_tasks[task_id] = task\n",
    "                            self.metrics['tasks_failed'] += 1\n",
    "                            logger.error(f\"Task {task_id} failed: {error}\")\n",
    "                    else:\n",
    "                        task.status = TaskStatus.COMPLETED\n",
    "                        task.result = result\n",
    "                        task.completed_at = time.time()\n",
    "                        self.completed_tasks[task_id] = task\n",
    "                        self.metrics['tasks_completed'] += 1\n",
    "                        logger.info(f\"Task {task_id} completed successfully\")\n",
    "                    \n",
    "                    # Remove from running tasks\n",
    "                    if task_id in self.running_tasks:\n",
    "                        del self.running_tasks[task_id]\n",
    "                    \n",
    "                    # Check dependents\n",
    "                    self._check_dependents(task_id)\n",
    "                    \n",
    "            except:\n",
    "                break\n",
    "\n",
    "    def _schedule_tasks(self):\n",
    "        \"\"\"Schedule tasks to available workers\"\"\"\n",
    "        with self.lock:\n",
    "            available_workers = len(self.workers) - len(self.running_tasks)\n",
    "            \n",
    "            while available_workers > 0 and self.pending_tasks:\n",
    "                prioritized_task = heapq.heappop(self.pending_tasks)\n",
    "                task = prioritized_task.task\n",
    "                \n",
    "                # Double-check dependencies\n",
    "                if task.dependencies and not all(dep_id in self.completed_tasks \n",
    "                                               for dep_id in task.dependencies):\n",
    "                    # Still waiting for dependencies, put back\n",
    "                    heapq.heappush(self.pending_tasks, prioritized_task)\n",
    "                    continue\n",
    "                \n",
    "                # Convert to serializable format and send to worker\n",
    "                serializable_task = task.to_serializable()\n",
    "                self.task_queue.put(serializable_task)\n",
    "                \n",
    "                task.status = TaskStatus.RUNNING\n",
    "                task.started_at = time.time()\n",
    "                self.running_tasks[task.task_id] = task\n",
    "                \n",
    "                available_workers -= 1\n",
    "                logger.info(f\"Scheduled task {task.task_id} to worker\")\n",
    "\n",
    "    def _check_dependents(self, completed_task_id: str):\n",
    "        \"\"\"Check if any dependent tasks can now be scheduled\"\"\"\n",
    "        if completed_task_id not in self.dependents:\n",
    "            return\n",
    "            \n",
    "        for dependent_id in self.dependents[completed_task_id]:\n",
    "            if dependent_id not in self.tasks:\n",
    "                continue\n",
    "                \n",
    "            dependent_task = self.tasks[dependent_id]\n",
    "            \n",
    "            # Check if all dependencies are now satisfied\n",
    "            if all(dep_id in self.completed_tasks \n",
    "                   for dep_id in dependent_task.dependencies):\n",
    "                # Task is ready to be scheduled\n",
    "                heapq.heappush(self.pending_tasks, \n",
    "                             PrioritizedTask(dependent_task.priority.value,\n",
    "                                           dependent_task.created_at, dependent_task))\n",
    "                logger.info(f\"Task {dependent_id} dependencies satisfied, queued for execution\")\n",
    "\n",
    "    def _check_worker_health(self):\n",
    "        \"\"\"Check and handle worker failures\"\"\"\n",
    "        dead_workers = []\n",
    "        \n",
    "        for worker_id, process in self.worker_processes.items():\n",
    "            if not process.is_alive():\n",
    "                dead_workers.append(worker_id)\n",
    "                logger.warning(f\"Worker {worker_id} died\")\n",
    "        \n",
    "        for worker_id in dead_workers:\n",
    "            # Reschedule tasks from dead worker\n",
    "            self._reschedule_worker_tasks(worker_id)\n",
    "            \n",
    "            # Remove dead worker\n",
    "            del self.workers[worker_id]\n",
    "            del self.worker_processes[worker_id]\n",
    "            self.metrics['workers_failed'] += 1\n",
    "            \n",
    "            # Replace worker\n",
    "            self._add_worker()\n",
    "\n",
    "    def _reschedule_worker_tasks(self, worker_id: str):\n",
    "        \"\"\"Reschedule tasks that were running on a failed worker\"\"\"\n",
    "        with self.lock:\n",
    "            tasks_to_reschedule = []\n",
    "            \n",
    "            for task_id, task in list(self.running_tasks.items()):\n",
    "                if task.worker_id == worker_id:\n",
    "                    tasks_to_reschedule.append(task)\n",
    "                    del self.running_tasks[task_id]\n",
    "                    \n",
    "                    # Reset task status\n",
    "                    task.status = TaskStatus.PENDING\n",
    "                    task.started_at = None\n",
    "                    task.worker_id = None\n",
    "            \n",
    "            # Add tasks back to pending queue\n",
    "            for task in tasks_to_reschedule:\n",
    "                heapq.heappush(self.pending_tasks, \n",
    "                             PrioritizedTask(task.priority.value, task.created_at, task))\n",
    "                logger.info(f\"Rescheduled task {task.task_id} from failed worker {worker_id}\")\n",
    "\n",
    "    def cancel_task(self, task_id: str) -> bool:\n",
    "        \"\"\"Cancel a pending or running task\"\"\"\n",
    "        with self.lock:\n",
    "            if task_id in self.tasks:\n",
    "                task = self.tasks[task_id]\n",
    "                \n",
    "                if task.status == TaskStatus.PENDING:\n",
    "                    # Remove from pending queue\n",
    "                    new_pending = [pt for pt in self.pending_tasks if pt.task.task_id != task_id]\n",
    "                    self.pending_tasks.clear()\n",
    "                    for pt in new_pending:\n",
    "                        heapq.heappush(self.pending_tasks, pt)\n",
    "                    \n",
    "                elif task.status == TaskStatus.RUNNING:\n",
    "                    # Can't cancel running tasks directly, mark for cleanup\n",
    "                    pass\n",
    "                \n",
    "                task.status = TaskStatus.CANCELLED\n",
    "                self.metrics['tasks_cancelled'] += 1\n",
    "                logger.info(f\"Cancelled task {task_id}\")\n",
    "                return True\n",
    "            \n",
    "            return False\n",
    "\n",
    "    def scale_workers(self, new_count: int):\n",
    "        \"\"\"Dynamically scale the number of workers\"\"\"\n",
    "        with self.lock:\n",
    "            current_count = len(self.workers)\n",
    "            \n",
    "            if new_count > current_count:\n",
    "                # Add workers\n",
    "                for _ in range(new_count - current_count):\n",
    "                    self._add_worker()\n",
    "                logger.info(f\"Scaled up to {new_count} workers\")\n",
    "                \n",
    "            elif new_count < current_count:\n",
    "                # Remove workers (gracefully)\n",
    "                workers_to_remove = current_count - new_count\n",
    "                removed = 0\n",
    "                \n",
    "                for worker_id in list(self.workers.keys()):\n",
    "                    if removed >= workers_to_remove:\n",
    "                        break\n",
    "                    \n",
    "                    # Send shutdown signal\n",
    "                    self.task_queue.put(None)\n",
    "                    removed += 1\n",
    "                    \n",
    "                logger.info(f\"Scaled down to {new_count} workers\")\n",
    "\n",
    "    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Get status of a specific task\"\"\"\n",
    "        with self.lock:\n",
    "            if task_id in self.tasks:\n",
    "                task = self.tasks[task_id]\n",
    "                return {\n",
    "                    'task_id': task.task_id,\n",
    "                    'status': task.status.value,\n",
    "                    'priority': task.priority.name,\n",
    "                    'created_at': task.created_at,\n",
    "                    'started_at': task.started_at,\n",
    "                    'completed_at': task.completed_at,\n",
    "                    'worker_id': task.worker_id,\n",
    "                    'result': task.result,\n",
    "                    'error': task.error,\n",
    "                    'retries_left': task.retries_left\n",
    "                }\n",
    "            return None\n",
    "\n",
    "    def get_system_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get overall system status and metrics\"\"\"\n",
    "        with self.lock:\n",
    "            return {\n",
    "                'workers_total': len(self.workers),\n",
    "                'workers_running': len([p for p in self.worker_processes.values() if p.is_alive()]),\n",
    "                'tasks_pending': len(self.pending_tasks),\n",
    "                'tasks_running': len(self.running_tasks),\n",
    "                'tasks_completed': len(self.completed_tasks),\n",
    "                'tasks_failed': len(self.failed_tasks),\n",
    "                'metrics': self.metrics.copy()\n",
    "            }\n",
    "\n",
    "    def wait_for_task(self, task_id: str, timeout: Optional[float] = None) -> Any:\n",
    "        \"\"\"Wait for a specific task to complete and return its result\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            status = self.get_task_status(task_id)\n",
    "            if not status:\n",
    "                raise ValueError(f\"Task {task_id} not found\")\n",
    "            \n",
    "            if status['status'] in [TaskStatus.COMPLETED.value, TaskStatus.FAILED.value, \n",
    "                                  TaskStatus.CANCELLED.value, TaskStatus.TIMEOUT.value]:\n",
    "                if status['status'] == TaskStatus.COMPLETED.value:\n",
    "                    return status['result']\n",
    "                elif status['status'] == TaskStatus.FAILED.value:\n",
    "                    raise Exception(f\"Task failed: {status['error']}\")\n",
    "                elif status['status'] == TaskStatus.CANCELLED.value:\n",
    "                    raise Exception(\"Task was cancelled\")\n",
    "                elif status['status'] == TaskStatus.TIMEOUT.value:\n",
    "                    raise Exception(\"Task timed out\")\n",
    "            \n",
    "            if timeout and (time.time() - start_time) > timeout:\n",
    "                raise TimeoutError(f\"Wait for task {task_id} timed out\")\n",
    "            \n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f977570c-646a-46cc-a97d-be84f27e0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Example demonstrating the distributed task scheduler\"\"\"\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    scheduler = DistributedTaskScheduler(num_workers=2)\n",
    "    scheduler.start()\n",
    "    \n",
    "    try:\n",
    "        # Submit independent tasks\n",
    "        task1 = scheduler.submit_task(long_running_task, (2, \"task1\"), \n",
    "                                    priority=TaskPriority.HIGH)\n",
    "        task2 = scheduler.submit_task(computation_task, (5, 10),\n",
    "                                    priority=TaskPriority.NORMAL)\n",
    "        \n",
    "        # Submit task with dependencies\n",
    "        task3 = scheduler.submit_task(long_running_task, (1, \"task3\"),\n",
    "                                    dependencies=[task1, task2],\n",
    "                                    priority=TaskPriority.NORMAL)\n",
    "        \n",
    "        # Submit task that will fail and retry\n",
    "        task4 = scheduler.submit_task(failing_task, retries=2,\n",
    "                                    priority=TaskPriority.LOW)\n",
    "        \n",
    "        # Submit task with timeout\n",
    "        task5 = scheduler.submit_task(long_running_task, (10, \"task5\"),\n",
    "                                    timeout=3.0, priority=TaskPriority.NORMAL)\n",
    "        \n",
    "        # Submit data processing task\n",
    "        task6 = scheduler.submit_task(data_processing_task, ([1, 2, 3, 4, 5],),\n",
    "                                    priority=TaskPriority.HIGH)\n",
    "        \n",
    "        print(\"Submitted tasks:\")\n",
    "        print(f\"Task1 (high priority): {task1}\")\n",
    "        print(f\"Task2 (normal): {task2}\")\n",
    "        print(f\"Task3 (depends on 1,2): {task3}\")\n",
    "        print(f\"Task4 (will fail, retries): {task4}\")\n",
    "        print(f\"Task5 (will timeout): {task5}\")\n",
    "        print(f\"Task6 (data processing): {task6}\")\n",
    "        \n",
    "        # Monitor progress\n",
    "        for i in range(30):\n",
    "            status = scheduler.get_system_status()\n",
    "            print(f\"\\n--- Iteration {i+1} ---\")\n",
    "            print(f\"Pending: {status['tasks_pending']}, \"\n",
    "                  f\"Running: {status['tasks_running']}, \"\n",
    "                  f\"Completed: {status['tasks_completed']}, \"\n",
    "                  f\"Failed: {status['tasks_failed']}\")\n",
    "            \n",
    "            # Check specific tasks\n",
    "            for task_id in [task1, task2, task3, task6]:\n",
    "                task_status = scheduler.get_task_status(task_id)\n",
    "                if task_status:\n",
    "                    print(f\"  {task_id}: {task_status['status']}\")\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Check if main tasks are done\n",
    "            task3_status = scheduler.get_task_status(task3)\n",
    "            if task3_status and task3_status['status'] == TaskStatus.COMPLETED.value:\n",
    "                print(f\"\\nTask3 completed with result: {task3_status['result']}\")\n",
    "                break\n",
    "        \n",
    "        # Scale workers dynamically\n",
    "        print(\"\\nScaling workers to 4...\")\n",
    "        scheduler.scale_workers(4)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        print(\"Scaling workers to 1...\")\n",
    "        scheduler.scale_workers(1)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Get final status\n",
    "        final_status = scheduler.get_system_status()\n",
    "        print(\"\\n=== Final System Status ===\")\n",
    "        for key, value in final_status.items():\n",
    "            if key == 'metrics':\n",
    "                print(\"Metrics:\")\n",
    "                for metric, count in value.items():\n",
    "                    print(f\"  {metric}: {count}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "                \n",
    "        # Try to get results for completed tasks\n",
    "        try:\n",
    "            result1 = scheduler.wait_for_task(task1, timeout=1)\n",
    "            print(f\"\\nTask1 result: {result1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not get Task1 result: {e}\")\n",
    "            \n",
    "        try:\n",
    "            result6 = scheduler.wait_for_task(task6, timeout=1)\n",
    "            print(f\"Task6 result: {result6}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not get Task6 result: {e}\")\n",
    "            \n",
    "    finally:\n",
    "        scheduler.stop()\n",
    "        print(\"\\nScheduler stopped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ca7786-71ce-475c-a7b6-d77464d05b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:34,679 - TaskScheduler - INFO - Started worker worker-81d75735\n",
      "2025-10-06 11:54:34,682 - TaskScheduler - INFO - Worker worker-81d75735 started\n",
      "2025-10-06 11:54:34,696 - TaskScheduler - INFO - Started worker worker-cbf776c6\n",
      "2025-10-06 11:54:34,701 - TaskScheduler - INFO - Task scheduler started\n",
      "2025-10-06 11:54:34,704 - TaskScheduler - INFO - Submitted task task-3dd57bf0 with priority HIGH\n",
      "2025-10-06 11:54:34,706 - TaskScheduler - INFO - Submitted task task-8a682add with priority NORMAL\n",
      "2025-10-06 11:54:34,708 - TaskScheduler - INFO - Submitted task task-9844d296 waiting for dependencies\n",
      "2025-10-06 11:54:34,709 - TaskScheduler - INFO - Submitted task task-109595f5 with priority LOW\n",
      "2025-10-06 11:54:34,711 - TaskScheduler - INFO - Submitted task task-eb033475 with priority NORMAL\n",
      "2025-10-06 11:54:34,712 - TaskScheduler - INFO - Submitted task task-3fee1860 with priority HIGH\n",
      "2025-10-06 11:54:34,722 - TaskScheduler - INFO - Scheduled task task-3dd57bf0 to worker\n",
      "2025-10-06 11:54:34,725 - TaskScheduler - INFO - Scheduled task task-3fee1860 to worker\n",
      "2025-10-06 11:54:34,712 - TaskScheduler - INFO - Worker worker-cbf776c6 started\n",
      "2025-10-06 11:54:34,723 - TaskScheduler - INFO - Worker worker-81d75735 executing task task-3dd57bf0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task task1 running for 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:34,737 - TaskScheduler - INFO - Worker worker-cbf776c6 executing task task-3fee1860\n",
      "2025-10-06 11:54:34,744 - TaskScheduler - INFO - Worker worker-cbf776c6 completed task task-3fee1860\n",
      "2025-10-06 11:54:34,835 - TaskScheduler - INFO - Task task-3fee1860 completed successfully\n",
      "2025-10-06 11:54:34,836 - TaskScheduler - INFO - Scheduled task task-8a682add to worker\n",
      "2025-10-06 11:54:34,838 - TaskScheduler - INFO - Worker worker-cbf776c6 executing task task-8a682add\n",
      "2025-10-06 11:54:34,854 - TaskScheduler - INFO - Worker worker-cbf776c6 completed task task-8a682add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted tasks:\n",
      "Task1 (high priority): task-3dd57bf0\n",
      "Task2 (normal): task-8a682add\n",
      "Task3 (depends on 1,2): task-9844d296\n",
      "Task4 (will fail, retries): task-109595f5\n",
      "Task5 (will timeout): task-eb033475\n",
      "Task6 (data processing): task-3fee1860\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Pending: 5, Running: 0, Completed: 0, Failed: 0\n",
      "  task-3dd57bf0: running\n",
      "  task-8a682add: pending\n",
      "  task-9844d296: pending\n",
      "  task-3fee1860: running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:34,939 - TaskScheduler - INFO - Task task-8a682add completed successfully\n",
      "2025-10-06 11:54:34,941 - TaskScheduler - INFO - Scheduled task task-eb033475 to worker\n",
      "2025-10-06 11:54:34,941 - TaskScheduler - INFO - Worker worker-cbf776c6 executing task task-eb033475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task task5 running for 10 seconds\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Pending: 1, Running: 2, Completed: 2, Failed: 0\n",
      "  task-3dd57bf0: running\n",
      "  task-8a682add: completed\n",
      "  task-9844d296: pending\n",
      "  task-3fee1860: completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:36,731 - TaskScheduler - INFO - Worker worker-81d75735 completed task task-3dd57bf0\n",
      "2025-10-06 11:54:36,746 - TaskScheduler - INFO - Task task-3dd57bf0 completed successfully\n",
      "2025-10-06 11:54:36,747 - TaskScheduler - INFO - Task task-9844d296 dependencies satisfied, queued for execution\n",
      "2025-10-06 11:54:36,748 - TaskScheduler - INFO - Scheduled task task-9844d296 to worker\n",
      "2025-10-06 11:54:36,748 - TaskScheduler - INFO - Worker worker-81d75735 executing task task-9844d296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task task3 running for 1 seconds\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Pending: 1, Running: 2, Completed: 2, Failed: 0\n",
      "  task-3dd57bf0: running\n",
      "  task-8a682add: completed\n",
      "  task-9844d296: pending\n",
      "  task-3fee1860: completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:37,793 - TaskScheduler - INFO - Worker worker-81d75735 completed task task-9844d296\n",
      "2025-10-06 11:54:37,857 - TaskScheduler - INFO - Task task-9844d296 completed successfully\n",
      "2025-10-06 11:54:37,858 - TaskScheduler - INFO - Scheduled task task-109595f5 to worker\n",
      "2025-10-06 11:54:37,859 - TaskScheduler - INFO - Worker worker-81d75735 executing task task-109595f5\n",
      "2025-10-06 11:54:37,863 - TaskScheduler - ERROR - Worker worker-81d75735 failed task task-109595f5: Failed to execute task task-109595f5: This task is designed to fail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 4 ---\n",
      "Pending: 1, Running: 2, Completed: 3, Failed: 0\n",
      "  task-3dd57bf0: completed\n",
      "  task-8a682add: completed\n",
      "  task-9844d296: running\n",
      "  task-3fee1860: completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:37,961 - TaskScheduler - INFO - Retrying task task-109595f5, 1 retries left\n",
      "2025-10-06 11:54:37,964 - TaskScheduler - INFO - Scheduled task task-109595f5 to worker\n",
      "2025-10-06 11:54:37,964 - TaskScheduler - INFO - Worker worker-81d75735 executing task task-109595f5\n",
      "2025-10-06 11:54:37,968 - TaskScheduler - ERROR - Worker worker-81d75735 failed task task-109595f5: Failed to execute task task-109595f5: This task is designed to fail\n",
      "2025-10-06 11:54:38,066 - TaskScheduler - INFO - Retrying task task-109595f5, 0 retries left\n",
      "2025-10-06 11:54:38,067 - TaskScheduler - INFO - Scheduled task task-109595f5 to worker\n",
      "2025-10-06 11:54:38,067 - TaskScheduler - INFO - Worker worker-81d75735 executing task task-109595f5\n",
      "2025-10-06 11:54:38,074 - TaskScheduler - ERROR - Worker worker-81d75735 failed task task-109595f5: Failed to execute task task-109595f5: This task is designed to fail\n",
      "2025-10-06 11:54:38,169 - TaskScheduler - ERROR - Task task-109595f5 failed: Failed to execute task task-109595f5: This task is designed to fail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task3 completed with result: Task task3 completed after 1s\n",
      "\n",
      "Scaling workers to 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:38,742 - TaskScheduler - INFO - Started worker worker-d608ce94\n",
      "2025-10-06 11:54:38,751 - TaskScheduler - INFO - Started worker worker-8eb6c89f\n",
      "2025-10-06 11:54:38,747 - TaskScheduler - INFO - Worker worker-d608ce94 started\n",
      "2025-10-06 11:54:38,761 - TaskScheduler - INFO - Scaled up to 4 workers\n",
      "2025-10-06 11:54:38,759 - TaskScheduler - INFO - Worker worker-8eb6c89f started\n",
      "2025-10-06 11:54:40,767 - TaskScheduler - INFO - Scaled down to 1 workers\n",
      "2025-10-06 11:54:40,768 - TaskScheduler - INFO - Worker worker-8eb6c89f stopped\n",
      "2025-10-06 11:54:40,769 - TaskScheduler - INFO - Worker worker-81d75735 stopped\n",
      "2025-10-06 11:54:40,769 - TaskScheduler - INFO - Worker worker-d608ce94 stopped\n",
      "2025-10-06 11:54:40,777 - TaskScheduler - WARNING - Worker worker-81d75735 died\n",
      "2025-10-06 11:54:40,779 - TaskScheduler - WARNING - Worker worker-8eb6c89f died\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling workers to 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:40,787 - TaskScheduler - INFO - Started worker worker-b695b129\n",
      "2025-10-06 11:54:40,805 - TaskScheduler - INFO - Started worker worker-10ef140c\n",
      "2025-10-06 11:54:40,800 - TaskScheduler - INFO - Worker worker-b695b129 started\n",
      "2025-10-06 11:54:40,811 - TaskScheduler - INFO - Worker worker-10ef140c started\n",
      "2025-10-06 11:54:40,916 - TaskScheduler - WARNING - Worker worker-d608ce94 died\n",
      "2025-10-06 11:54:40,923 - TaskScheduler - INFO - Started worker worker-f96a2d87\n",
      "2025-10-06 11:54:40,929 - TaskScheduler - INFO - Worker worker-f96a2d87 started\n",
      "2025-10-06 11:54:42,770 - TaskScheduler - INFO - Worker worker-b695b129 stopped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final System Status ===\n",
      "workers_total: 4\n",
      "workers_running: 4\n",
      "tasks_pending: 0\n",
      "tasks_running: 1\n",
      "tasks_completed: 4\n",
      "tasks_failed: 1\n",
      "Metrics:\n",
      "  tasks_completed: 4\n",
      "  tasks_failed: 1\n",
      "  tasks_cancelled: 0\n",
      "  tasks_timed_out: 0\n",
      "  workers_created: 7\n",
      "  workers_failed: 3\n",
      "\n",
      "Task1 result: Task task1 completed after 2s\n",
      "Task6 result: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:54:44,957 - TaskScheduler - WARNING - Worker worker-cbf776c6 timeout on task task-eb033475\n",
      "2025-10-06 11:54:47,774 - TaskScheduler - INFO - Worker worker-f96a2d87 stopped\n",
      "2025-10-06 11:54:47,774 - TaskScheduler - INFO - Worker worker-10ef140c stopped\n",
      "2025-10-06 11:54:47,786 - TaskScheduler - INFO - Task scheduler stopped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scheduler stopped\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8676dd-3e37-4b0c-b0fa-943002e116d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
